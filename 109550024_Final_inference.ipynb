{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMRegressor\n",
    "import catboost as cb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "deal with the missing data and fill-in the NAN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some columns in the train.csv and test.csv has the missing data\n",
    "# we have to deal with the missing data to get the better performance of the model\n",
    "# split: the size of the val data\n",
    "def dealing_with_missingData(T, NAN_var, target, split):\n",
    "    # a shallow copy of the table(the csv data)\n",
    "    missingData = T.copy() \n",
    "\n",
    "    # find the position that is null value\n",
    "    missingTarget = missingData[missingData[NAN_var].isnull()] \n",
    "    # use isnull().sum(axis=1) can get the number of the NAN data\n",
    "    missingData = missingData[(missingData.isnull().sum(axis=1) <1)]\n",
    "\n",
    "    # drop the column that has nan values\n",
    "    x_missing = missingData.drop([NAN_var, target], axis=1) \n",
    "    # do the same thing for the label\n",
    "    y_missing = missingData[NAN_var]\n",
    "    \n",
    "    # then we split the data to train and test\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x_missing, y_missing, test_size=split, random_state=42, shuffle=True)\n",
    "    \n",
    "    # then return the result\n",
    "    return x_train, x_val, y_train, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as the function name stating, we fill the NAN position with some value\n",
    "def fillNAN(T, T_NAN, model, NAN_var, target):\n",
    "    # first we get the columns with nan values\n",
    "    missing_target = T[T[NAN_var].isnull()]\n",
    "    miss_train = missing_target.drop([NAN_var, target], axis=1)\n",
    "    pred = model.predict(miss_train)\n",
    "    \n",
    "    # isna() is used to check the missing value\n",
    "    nans = T[NAN_var].isna()\n",
    "    T_NAN.loc[nans, NAN_var] = pred\n",
    "    \n",
    "    return T_NAN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load the csv data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the csv data train.csv and test.csv\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "sample_submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating target variable for test data and fill in it with some value\n",
    "test['failure'] = 2\n",
    "data = train.append(test)\n",
    "\n",
    "# we can use .info() to see the non-null count\n",
    "# data.info()\n",
    "\n",
    "train = train.drop(['id'], axis=1)\n",
    "data = data.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a shallow copy\n",
    "df = data.copy()\n",
    "\n",
    "# product_code has A, B, C... types of category\n",
    "# cat. codes is for categorical data and get_dummies is for object\n",
    "df['product_code'] = df['product_code'].astype('category').cat.codes\n",
    "df['attribute_0'] = df['attribute_0'].astype('category').cat.codes\n",
    "\n",
    "# create the column calculating by multiply attribute_2 and attribute_3\n",
    "df['atr_2 * atr3'] = df['attribute_2'] * df['attribute_3']\n",
    "\n",
    "# use drop function to drop some columns\n",
    "# these column has some missing data, and the content of the data should be modify\n",
    "df = df.drop(['attribute_1', 'attribute_2', 'attribute_3', 'measurement_2', 'measurement_8', 'measurement_12', 'measurement_15', 'measurement_16'], axis=1)\n",
    "# we can use .info() to see the non-null count\n",
    "# df.info()\n",
    "\n",
    "# a shallow copy\n",
    "df_nan = df.copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dealing with measurement_4 column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deal with measurement_4 column\n",
    "x_train, x_val, y_train, y_val = dealing_with_missingData(df, 'measurement_4', 'failure', 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the LinearRegression model\n",
    "reg_measurement4 = LinearRegression().fit(x_train, y_train)\n",
    "reg_measurement4.score(x_train, y_train)\n",
    "pred_reg = reg_measurement4.predict(x_val)\n",
    "\n",
    "# get the mean squared error\n",
    "mean_squared_error(y_val, pred_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use CatBoostRegressor model\n",
    "cat_measurement4 = cb.CatBoostRegressor(verbose=False, learning_rate = 0.055)\n",
    "cat_measurement4.fit(x_train, y_train)\n",
    "pred_cat = cat_measurement4.predict(x_val)\n",
    "\n",
    "# get the mean squared error\n",
    "mean_squared_error(y_val, pred_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in the NAN values\n",
    "# the mean square error of CatBoostRegressor is smaller, so use CatBoostRegressor model \n",
    "df_nan = fillNAN(df, df_nan, cat_measurement4, 'measurement_4', 'failure')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dealing with measurement_11 column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = dealing_with_missingData(df, 'measurement_11', 'failure', 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_measurement11 = LinearRegression().fit(x_train, y_train)\n",
    "reg_measurement11.score(x_train, y_train)\n",
    "pred_reg = reg_measurement11.predict(x_val)\n",
    "\n",
    "mean_squared_error(y_val, pred_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_measurement11 = cb.CatBoostRegressor(verbose=False, learning_rate = 0.02)\n",
    "cat_measurement11.fit(x_train, y_train)\n",
    "pred_cat = cat_measurement11.predict(x_val)\n",
    "\n",
    "mean_squared_error(y_val, pred_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the mean square error of CatBoostRegressor is smaller, so use CatBoostRegressor model \n",
    "df_nan = fillNAN(df, df_nan, cat_measurement11, 'measurement_11', 'failure')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dealing with measurement_5 column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = dealing_with_missingData(df, 'measurement_5', 'failure', 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_measurement5 = LinearRegression().fit(x_train, y_train)\n",
    "reg_measurement5.score(x_train, y_train)\n",
    "pred_reg = reg_measurement5.predict(x_val)\n",
    "\n",
    "mean_squared_error(y_val, pred_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_measurement5 = cb.CatBoostRegressor(verbose=False, learning_rate = 0.04)\n",
    "cat_measurement5.fit(x_train, y_train)\n",
    "pred_cat = cat_measurement5.predict(x_val)\n",
    "\n",
    "mean_squared_error(y_val, pred_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the mean square error of CatBoostRegressor is smaller, so use CatBoostRegressor model \n",
    "df_nan = fillNAN(df, df_nan, cat_measurement5, 'measurement_5', 'failure')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dealing with measurement_7 column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = dealing_with_missingData(df, 'measurement_7', 'failure', 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_measurement7 = LinearRegression().fit(x_train, y_train)\n",
    "reg_measurement7.score(x_train, y_train)\n",
    "pred_reg = reg_measurement7.predict(x_val)\n",
    "\n",
    "mean_squared_error(y_val, pred_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_measurement7 = cb.CatBoostRegressor(verbose=False, learning_rate = 0.03)\n",
    "cat_measurement7.fit(x_train, y_train)\n",
    "pred_cat = cat_measurement7.predict(x_val)\n",
    "\n",
    "mean_squared_error(y_val, pred_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the mean square error of CatBoostRegressor is smaller, so use CatBoostRegressor model \n",
    "df_nan = fillNAN(df, df_nan, cat_measurement7, 'measurement_7', 'failure')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dealing with measurement_14 column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = dealing_with_missingData(df, 'measurement_14', 'failure', 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_measurement14 = LinearRegression().fit(x_train, y_train)\n",
    "reg_measurement14.score(x_train, y_train)\n",
    "pred_reg = reg_measurement14.predict(x_val)\n",
    "\n",
    "mean_squared_error(y_val, pred_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we use LGBMRegressor to deal with measurement14 column\n",
    "lite_measurement14 = LGBMRegressor(min_data_in_leaf=8, num_iterations=60)\n",
    "lite_measurement14.fit(x_train, y_train)\n",
    "pred_lite = lite_measurement14.predict(x_val)\n",
    "\n",
    "mean_squared_error(y_val, pred_lite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the mean square error of LGBMRegressor is smaller, so use LGBMRegressor model \n",
    "df_nan = fillNAN(df, df_nan, lite_measurement14, 'measurement_14', 'failure')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dealing with measurement_17 column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = dealing_with_missingData(df, 'measurement_17', 'failure', 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_measurement17 = LinearRegression().fit(x_train, y_train)\n",
    "reg_measurement17.score(x_train, y_train)\n",
    "pred_reg = reg_measurement17.predict(x_val)\n",
    "\n",
    "mean_squared_error(y_val, pred_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_measurement17 = cb.CatBoostRegressor(verbose=False, learning_rate = 0.03)\n",
    "cat_measurement17.fit(x_train, y_train)\n",
    "pred_cat = cat_measurement17.predict(x_val)\n",
    "\n",
    "mean_squared_error(y_val, pred_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the mean square error of CatBoostRegressor is smaller, so use CatBoostRegressor model \n",
    "df_nan = fillNAN(df, df_nan, cat_measurement17, 'measurement_17', 'failure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_nan\n",
    "\n",
    "# we can use .info() to see the non-null count\n",
    "# df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "processing for more feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.isnull().sum(axis=1) is used to calculate all the missing value of columns\n",
    "df = df[(df.isnull().sum(axis=1) <= 1) | (df.failure == 2)]\n",
    "\n",
    "df = df[(df['loading'] < 300) | (df['failure'] == 2)]\n",
    "df = df[(df['measurement_1'] < 27) | (df['failure'] == 2)]\n",
    "\n",
    "# create some columns\n",
    "df['loading * mesh6'] = ((df['loading'] - df['loading'].min()) / df['loading'].max()) * ((df['measurement_6'] - df['measurement_6'].min()) / df['measurement_6'].max())\n",
    "df['loading * mesh6'] = df['measurement_17'] * df['loading * mesh6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the failure that is not equal to 2\n",
    "y = df[df.failure != 2].failure.values\n",
    "# test_df get the failure that is equal to 2\n",
    "test_df = df[df.failure == 2]\n",
    "# get the column that the failure is not equal to 2 and drop the failure and product_code column\n",
    "X_res = df[df.failure != 2].drop(['failure',  'product_code'], axis=1)\n",
    "\n",
    "# drop the failure column and product_code(failure column is the label and product_code is not important for training)\n",
    "x_test = test_df.drop(['failure', 'product_code'], axis=1)\n",
    "\n",
    "# import SimpleImputer\n",
    "# SimpleImputer can fill in the missing value\n",
    "from sklearn.impute import SimpleImputer\n",
    "# the strategy is mean represents that we are going to use mean to fill in the missing data\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer = imputer.fit(X_res)\n",
    "  \n",
    "X = imputer.transform(X_res)\n",
    "\n",
    "# same for the test data\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer = imputer.fit(x_test)\n",
    "X_test = imputer.transform(x_test)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.01, random_state=42, shuffle=True, stratify= y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mutual_info_classif is used to Estimate mutual information for a discrete target variable.\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    " \n",
    "X_T = pd.DataFrame(data=X, columns = X_res.columns)\n",
    "\n",
    "MI_score = mutual_info_classif(X_T, y)\n",
    "MI_score = pd.Series(MI_score, name=\"MI Scores\", index=X_T.columns)\n",
    "\n",
    "# sort the values of ascending order\n",
    "MI_score = MI_score.sort_values(ascending=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "# first import pickle\n",
    "import pickle\n",
    "\n",
    "pkl_filename=\"LR_model.pkl\"\n",
    "\n",
    "with open(pkl_filename, 'rb') as file:\n",
    "    pickled_LR_model = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict = pickled_LR_model.predict_proba(X_test)[:,1]\n",
    "sample_submission['failure'] = test_predict\n",
    "sample_submission.to_csv('109550024.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cf92aa13fedf815d5c8dd192b8d835913fde3e8bc926b2a0ad6cc74ef2ba3ca2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
