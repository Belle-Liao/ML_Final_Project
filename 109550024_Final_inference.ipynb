{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Installing feature-engine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: feature-engine in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from feature-engine) (1.7.3)\n",
      "Requirement already satisfied: pandas>=1.0.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from feature-engine) (1.3.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from feature-engine) (1.0.2)\n",
      "Requirement already satisfied: statsmodels>=0.11.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from feature-engine) (0.13.5)\n",
      "Requirement already satisfied: numpy>=1.18.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from feature-engine) (1.22.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas>=1.0.3->feature-engine) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas>=1.0.3->feature-engine) (2.8.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn>=1.0.0->feature-engine) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn>=1.0.0->feature-engine) (1.2.0)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from statsmodels>=0.11.1->feature-engine) (21.3)\n",
      "Requirement already satisfied: patsy>=0.5.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from statsmodels>=0.11.1->feature-engine) (0.5.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from packaging>=21.3->statsmodels>=0.11.1->feature-engine) (3.0.6)\n",
      "Requirement already satisfied: six in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from patsy>=0.5.2->statsmodels>=0.11.1->feature-engine) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "!pip install feature-engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMRegressor\n",
    "import catboost as cb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dealing with the missing data and fill-in the NAN values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some columns in the train.csv and test.csv has the missing data\n",
    "# we have to deal with the missing data to get the better performance of the model\n",
    "# split: the size of the val data\n",
    "def dealing_with_missingData(T, NAN_var, target, split):\n",
    "    # a shallow copy of the table(the csv data)\n",
    "    missingData = T.copy() \n",
    "\n",
    "    # find the position that is null value\n",
    "    missingTarget = missingData[missingData[NAN_var].isnull()] \n",
    "    # use isnull().sum(axis=1) can get the number of the NAN data\n",
    "    missingData = missingData[(missingData.isnull().sum(axis=1) <1)]\n",
    "\n",
    "    # drop the column that has nan values\n",
    "    x_missing = missingData.drop([NAN_var, target], axis=1) \n",
    "    # do the same thing for the label\n",
    "    y_missing = missingData[NAN_var]\n",
    "    \n",
    "    # then we split the data to train and test\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x_missing, y_missing, test_size=split, random_state=42, shuffle=True)\n",
    "    \n",
    "    # then return the result\n",
    "    return x_train, x_val, y_train, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as the function name stating, we fill the NAN position with some value\n",
    "def fillNAN(T, T_NAN, model, NAN_var, target):\n",
    "    # first we get the columns with nan values\n",
    "    missing_target = T[T[NAN_var].isnull()]\n",
    "    miss_train = missing_target.drop([NAN_var, target], axis=1)\n",
    "    pred = model.predict(miss_train)\n",
    "    \n",
    "    # isna() is used to check the missing value\n",
    "    nans = T[NAN_var].isna()\n",
    "    T_NAN.loc[nans, NAN_var] = pred\n",
    "    \n",
    "    return T_NAN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading the csv data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the csv data train.csv and test.csv\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "sample_submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating target variable for test data and fill in it with some value\n",
    "test['failure'] = 2\n",
    "data = train.append(test)\n",
    "\n",
    "# we can use .info() to see the non-null count\n",
    "# data.info()\n",
    "\n",
    "train = train.drop(['id'], axis=1)\n",
    "data = data.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a shallow copy\n",
    "df = data.copy()\n",
    "\n",
    "# product_code has A, B, C... types of category\n",
    "# cat.codes is for categorical data and get_dummies is for object\n",
    "df['product_code'] = df['product_code'].astype('category').cat.codes\n",
    "df['attribute_0'] = df['attribute_0'].astype('category').cat.codes\n",
    "\n",
    "# create the column calculating by multiply attribute_2 and attribute_3\n",
    "df['atr_2 * atr3'] = df['attribute_2'] * df['attribute_3']\n",
    "\n",
    "# use drop function to drop some columns\n",
    "# these column has some missing data, and the content of the data should be modify\n",
    "df = df.drop(['attribute_1', 'attribute_2', 'attribute_3', 'measurement_2', 'measurement_8', 'measurement_12', 'measurement_15', 'measurement_16'], axis=1)\n",
    "# we can use .info() to see the non-null count\n",
    "# df.info()\n",
    "\n",
    "# a shallow copy\n",
    "df_nan = df.copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dealing with measurement_4 column**\n",
    "\n",
    "Use LinearRegression model and CatBoostRegressor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deal with measurement_4 column\n",
    "x_train, x_val, y_train, y_val = dealing_with_missingData(df, 'measurement_4', 'failure', 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.954559257221399"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the LinearRegression model\n",
    "reg_measurement4 = LinearRegression().fit(x_train, y_train)\n",
    "reg_measurement4.score(x_train, y_train)\n",
    "pred_reg = reg_measurement4.predict(x_val)\n",
    "\n",
    "# get the mean squared error\n",
    "mean_squared_error(y_val, pred_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.698175744255882"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use CatBoostRegressor model\n",
    "cat_measurement4 = cb.CatBoostRegressor(verbose=False, learning_rate = 0.055)\n",
    "cat_measurement4.fit(x_train, y_train)\n",
    "pred_cat = cat_measurement4.predict(x_val)\n",
    "\n",
    "# get the mean squared error\n",
    "mean_squared_error(y_val, pred_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in the NAN values\n",
    "# the mean square error of CatBoostRegressor is smaller, so use CatBoostRegressor model \n",
    "df_nan = fillNAN(df, df_nan, cat_measurement4, 'measurement_4', 'failure')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dealing with measurement_11 column**\n",
    "\n",
    "Use LinearRegression model and CatBoostRegressor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = dealing_with_missingData(df, 'measurement_11', 'failure', 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1227127008961553"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_measurement11 = LinearRegression().fit(x_train, y_train)\n",
    "reg_measurement11.score(x_train, y_train)\n",
    "pred_reg = reg_measurement11.predict(x_val)\n",
    "\n",
    "mean_squared_error(y_val, pred_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9332449278245774"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_measurement11 = cb.CatBoostRegressor(verbose=False, learning_rate = 0.02)\n",
    "cat_measurement11.fit(x_train, y_train)\n",
    "pred_cat = cat_measurement11.predict(x_val)\n",
    "\n",
    "mean_squared_error(y_val, pred_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the mean square error of CatBoostRegressor is smaller, so use CatBoostRegressor model \n",
    "df_nan = fillNAN(df, df_nan, cat_measurement11, 'measurement_11', 'failure')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dealing with measurement_5 column**\n",
    "\n",
    "Use LinearRegression model and CatBoostRegressor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = dealing_with_missingData(df, 'measurement_5', 'failure', 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8165184577746109"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_measurement5 = LinearRegression().fit(x_train, y_train)\n",
    "reg_measurement5.score(x_train, y_train)\n",
    "pred_reg = reg_measurement5.predict(x_val)\n",
    "\n",
    "mean_squared_error(y_val, pred_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5737602808692598"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_measurement5 = cb.CatBoostRegressor(verbose=False, learning_rate = 0.04)\n",
    "cat_measurement5.fit(x_train, y_train)\n",
    "pred_cat = cat_measurement5.predict(x_val)\n",
    "\n",
    "mean_squared_error(y_val, pred_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the mean square error of CatBoostRegressor is smaller, so use CatBoostRegressor model \n",
    "df_nan = fillNAN(df, df_nan, cat_measurement5, 'measurement_5', 'failure')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dealing with measurement_7 column**\n",
    "\n",
    "Use LinearRegression model and CatBoostRegressor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = dealing_with_missingData(df, 'measurement_7', 'failure', 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7903542041278784"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_measurement7 = LinearRegression().fit(x_train, y_train)\n",
    "reg_measurement7.score(x_train, y_train)\n",
    "pred_reg = reg_measurement7.predict(x_val)\n",
    "\n",
    "mean_squared_error(y_val, pred_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5902445836095019"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_measurement7 = cb.CatBoostRegressor(verbose=False, learning_rate = 0.03)\n",
    "cat_measurement7.fit(x_train, y_train)\n",
    "pred_cat = cat_measurement7.predict(x_val)\n",
    "\n",
    "mean_squared_error(y_val, pred_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the mean square error of CatBoostRegressor is smaller, so use CatBoostRegressor model \n",
    "df_nan = fillNAN(df, df_nan, cat_measurement7, 'measurement_7', 'failure')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dealing with measurement_14 column**\n",
    "\n",
    "Use LinearRegression model and LGBMRegressor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = dealing_with_missingData(df, 'measurement_14', 'failure', 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.347354085510614"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_measurement14 = LinearRegression().fit(x_train, y_train)\n",
    "reg_measurement14.score(x_train, y_train)\n",
    "pred_reg = reg_measurement14.predict(x_val)\n",
    "\n",
    "mean_squared_error(y_val, pred_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.1926231588211045"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here we use LGBMRegressor to deal with measurement14 column\n",
    "lite_measurement14 = LGBMRegressor(min_data_in_leaf=8, num_iterations=60)\n",
    "lite_measurement14.fit(x_train, y_train)\n",
    "pred_lite = lite_measurement14.predict(x_val)\n",
    "\n",
    "mean_squared_error(y_val, pred_lite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the mean square error of LGBMRegressor is smaller, so use LGBMRegressor model \n",
    "df_nan = fillNAN(df, df_nan, lite_measurement14, 'measurement_14', 'failure')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dealing with measurement_17 column**\n",
    "\n",
    "Use LinearRegression model and CatBoostRegressor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = dealing_with_missingData(df, 'measurement_17', 'failure', 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9301.12723736656"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_measurement17 = LinearRegression().fit(x_train, y_train)\n",
    "reg_measurement17.score(x_train, y_train)\n",
    "pred_reg = reg_measurement17.predict(x_val)\n",
    "\n",
    "mean_squared_error(y_val, pred_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3965.5664856310304"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_measurement17 = cb.CatBoostRegressor(verbose=False, learning_rate = 0.03)\n",
    "cat_measurement17.fit(x_train, y_train)\n",
    "pred_cat = cat_measurement17.predict(x_val)\n",
    "\n",
    "mean_squared_error(y_val, pred_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the mean square error of CatBoostRegressor is smaller, so use CatBoostRegressor model \n",
    "df_nan = fillNAN(df, df_nan, cat_measurement17, 'measurement_17', 'failure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_nan\n",
    "\n",
    "# we can use .info() to see the non-null count\n",
    "# df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Processing for more feature engineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.isnull().sum(axis=1) is used to calculate all the missing value of columns\n",
    "df = df[(df.isnull().sum(axis=1) <= 1) | (df.failure == 2)]\n",
    "\n",
    "df = df[(df['loading'] < 300) | (df['failure'] == 2)]\n",
    "df = df[(df['measurement_1'] < 27) | (df['failure'] == 2)]\n",
    "\n",
    "# create some columns\n",
    "df['loading * mesh6'] = ((df['loading'] - df['loading'].min()) / df['loading'].max()) * ((df['measurement_6'] - df['measurement_6'].min()) / df['measurement_6'].max())\n",
    "df['loading * mesh6'] = df['measurement_17'] * df['loading * mesh6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the failure that is not equal to 2\n",
    "y = df[df.failure != 2].failure.values\n",
    "# test_df get the failure that is equal to 2\n",
    "test_df = df[df.failure == 2]\n",
    "# get the column that the failure is not equal to 2 and drop the failure and product_code column\n",
    "X_res = df[df.failure != 2].drop(['failure',  'product_code'], axis=1)\n",
    "\n",
    "# drop the failure column and product_code(failure column is the label and product_code is not important for training)\n",
    "x_test = test_df.drop(['failure', 'product_code'], axis=1)\n",
    "\n",
    "# import SimpleImputer\n",
    "# SimpleImputer can fill in the missing value\n",
    "from sklearn.impute import SimpleImputer\n",
    "# the strategy is mean represents that we are going to use mean to fill in the missing data\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer = imputer.fit(X_res)\n",
    "  \n",
    "X = imputer.transform(X_res)\n",
    "\n",
    "# same for the test data\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer = imputer.fit(x_test)\n",
    "X_test = imputer.transform(x_test)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.01, random_state=42, shuffle=True, stratify= y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mutual_info_classif is used to Estimate mutual information for a discrete target variable.\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    " \n",
    "X_T = pd.DataFrame(data=X, columns = X_res.columns)\n",
    "\n",
    "MI_score = mutual_info_classif(X_T, y)\n",
    "MI_score = pd.Series(MI_score, name=\"MI Scores\", index=X_T.columns)\n",
    "\n",
    "# sort the values of ascending order\n",
    "MI_score = MI_score.sort_values(ascending=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "# first import pickle\n",
    "import pickle\n",
    "\n",
    "pkl_filename=\"LR_model.pkl\"\n",
    "\n",
    "with open(pkl_filename, 'rb') as file:\n",
    "    pickled_LR_model = pickle.load(file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generating the submission csv file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict = pickled_LR_model.predict_proba(X_test)[:,1]\n",
    "sample_submission['failure'] = test_predict\n",
    "sample_submission.to_csv('109550024.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cf92aa13fedf815d5c8dd192b8d835913fde3e8bc926b2a0ad6cc74ef2ba3ca2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
