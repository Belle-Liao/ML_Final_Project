{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMRegressor\n",
    "import catboost as cb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "deal with the missing data and fill-in the NAN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some columns in the train.csv and test.csv has the missing data\n",
    "# we have to deal with the missing data to get the better performance of the model\n",
    "# split: the size of the val data\n",
    "def dealing_with_missingData(T, NAN_var, target, split):\n",
    "    # a shallow copy of the table(the csv data)\n",
    "    missingData = T.copy() \n",
    "\n",
    "    # find the position that is null value\n",
    "    missingTarget = missingData[missingData[NAN_var].isnull()] \n",
    "    # use isnull().sum(axis=1) can get the number of the NAN data\n",
    "    missingData = missingData[(missingData.isnull().sum(axis=1) <1)]\n",
    "\n",
    "    # drop the column that has nan values\n",
    "    x_missing = missingData.drop([NAN_var, target], axis=1) \n",
    "    # do the same thing for the label\n",
    "    y_missing = missingData[NAN_var]\n",
    "    \n",
    "    # then we split the data to train and test\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x_missing, y_missing, test_size=split, random_state=42, shuffle=True)\n",
    "    \n",
    "    # then return the result\n",
    "    return x_train, x_val, y_train, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as the function name stating, we fill the NAN position with some value\n",
    "def fillNAN(T, T_NAN, model, NAN_var, target):\n",
    "    # first we get the columns with nan values\n",
    "    missing_target = T[T[NAN_var].isnull()]\n",
    "    miss_train = missing_target.drop([NAN_var, target], axis=1)\n",
    "    pred = model.predict(miss_train)\n",
    "    \n",
    "    # isna() is used to check the missing value\n",
    "    nans = T[NAN_var].isna()\n",
    "    T_NAN.loc[nans, NAN_var] = pred\n",
    "    \n",
    "    return T_NAN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load the csv data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the csv data train.csv and test.csv\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "sample_submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating target variable for test data and fill in it with some value\n",
    "test['failure'] = 2\n",
    "data = train.append(test)\n",
    "\n",
    "# we can use .info() to see the non-null count\n",
    "# data.info()\n",
    "\n",
    "train = train.drop(['id'], axis=1)\n",
    "data = data.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a shallow copy\n",
    "df = data.copy()\n",
    "\n",
    "# product_code has A, B, C... types of category\n",
    "# cat. codes is for categorical data and get_dummies is for object\n",
    "df['product_code'] = df['product_code'].astype('category').cat.codes\n",
    "df['attribute_0'] = df['attribute_0'].astype('category').cat.codes\n",
    "\n",
    "# create the column calculating by multiply attribute_2 and attribute_3\n",
    "df['atr_2 * atr3'] = df['attribute_2'] * df['attribute_3']\n",
    "\n",
    "# use drop function to drop some columns\n",
    "# these column has some missing data, and the content of the data should be modify\n",
    "df = df.drop(['attribute_1', 'attribute_2', 'attribute_3', 'measurement_2', 'measurement_8', 'measurement_12', 'measurement_15', 'measurement_16'], axis=1)\n",
    "# we can use .info() to see the non-null count\n",
    "# df.info()\n",
    "\n",
    "# a shallow copy\n",
    "df_nan = df.copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dealing with measurement_4 column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deal with measurement_4 column\n",
    "x_train, x_val, y_train, y_val = dealing_with_missingData(df, 'measurement_4', 'failure', 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.954559257221399"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the LinearRegression model\n",
    "reg_measurement4 = LinearRegression().fit(x_train, y_train)\n",
    "reg_measurement4.score(x_train, y_train)\n",
    "pred_reg = reg_measurement4.predict(x_val)\n",
    "\n",
    "# get the mean squared error\n",
    "mean_squared_error(y_val, pred_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.691084406719754"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use CatBoostRegressor model\n",
    "cat_measurement4 = cb.CatBoostRegressor(verbose=False, learning_rate = 0.05)\n",
    "cat_measurement4.fit(x_train, y_train)\n",
    "pred_cat = cat_measurement4.predict(x_val)\n",
    "\n",
    "# get the mean squared error\n",
    "mean_squared_error(y_val, pred_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in the NAN values\n",
    "# the mean square error of CatBoostRegressor is smaller, so use CatBoostRegressor model \n",
    "df_nan = fillNAN(df, df_nan, cat_measurement4, 'measurement_4', 'failure')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dealing with measurement_11 column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = dealing_with_missingData(df, 'measurement_11', 'failure', 0.08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.292342662988236"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_measurement11 = LinearRegression().fit(x_train, y_train)\n",
    "reg_measurement11.score(x_train, y_train)\n",
    "pred_reg = reg_measurement11.predict(x_val)\n",
    "\n",
    "mean_squared_error(y_val, pred_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.079140306426748"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_measurement11 = cb.CatBoostRegressor(verbose=False, learning_rate = 0.04)\n",
    "cat_measurement11.fit(x_train, y_train)\n",
    "pred_cat = cat_measurement11.predict(x_val)\n",
    "\n",
    "mean_squared_error(y_val, pred_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the mean square error of CatBoostRegressor is smaller, so use CatBoostRegressor model \n",
    "df_nan = fillNAN(df, df_nan, cat_measurement11, 'measurement_11', 'failure')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dealing with measurement_5 column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = dealing_with_missingData(df, 'measurement_5', 'failure', 0.008)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8272093299077914"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_measurement5 = LinearRegression().fit(x_train, y_train)\n",
    "reg_measurement5.score(x_train, y_train)\n",
    "pred_reg = reg_measurement5.predict(x_val)\n",
    "\n",
    "mean_squared_error(y_val, pred_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5593132698297004"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_measurement5 = cb.CatBoostRegressor(verbose=False, learning_rate = 0.046)\n",
    "cat_measurement5.fit(x_train, y_train)\n",
    "pred_cat = cat_measurement5.predict(x_val)\n",
    "\n",
    "mean_squared_error(y_val, pred_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the mean square error of CatBoostRegressor is smaller, so use CatBoostRegressor model \n",
    "df_nan = fillNAN(df, df_nan, cat_measurement5, 'measurement_5', 'failure')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dealing with measurement_7 column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = dealing_with_missingData(df, 'measurement_7', 'failure', 0.009)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7438138496406586"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_measurement7 = LinearRegression().fit(x_train, y_train)\n",
    "reg_measurement7.score(x_train, y_train)\n",
    "pred_reg = reg_measurement7.predict(x_val)\n",
    "\n",
    "mean_squared_error(y_val, pred_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.556530797206808"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_measurement7 = cb.CatBoostRegressor(verbose=False, learning_rate = 0.032)\n",
    "cat_measurement7.fit(x_train, y_train)\n",
    "pred_cat = cat_measurement7.predict(x_val)\n",
    "\n",
    "mean_squared_error(y_val, pred_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the mean square error of CatBoostRegressor is smaller, so use CatBoostRegressor model \n",
    "df_nan = fillNAN(df, df_nan, cat_measurement7, 'measurement_7', 'failure')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dealing with measurement_14 column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = dealing_with_missingData(df, 'measurement_14', 'failure', 0.015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.277716491015243"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_measurement14 = LinearRegression().fit(x_train, y_train)\n",
    "reg_measurement14.score(x_train, y_train)\n",
    "pred_reg = reg_measurement14.predict(x_val)\n",
    "\n",
    "mean_squared_error(y_val, pred_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=8, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.0991118621924887"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here we use LGBMRegressor to deal with measurement14 column\n",
    "lite_measurement14 = LGBMRegressor(min_data_in_leaf=8, num_iterations=80)\n",
    "lite_measurement14.fit(x_train, y_train)\n",
    "pred_lite = lite_measurement14.predict(x_val)\n",
    "\n",
    "mean_squared_error(y_val, pred_lite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the mean square error of LGBMRegressor is smaller, so use LGBMRegressor model \n",
    "df_nan = fillNAN(df, df_nan, lite_measurement14, 'measurement_14', 'failure')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dealing with measurement_17 column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = dealing_with_missingData(df, 'measurement_17', 'failure', 0.025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8554.058551899949"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_measurement17 = LinearRegression().fit(x_train, y_train)\n",
    "reg_measurement17.score(x_train, y_train)\n",
    "pred_reg = reg_measurement17.predict(x_val)\n",
    "\n",
    "mean_squared_error(y_val, pred_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4059.609139912901"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_measurement17 = cb.CatBoostRegressor(verbose=False, learning_rate = 0.042)\n",
    "cat_measurement17.fit(x_train, y_train)\n",
    "pred_cat = cat_measurement17.predict(x_val)\n",
    "\n",
    "mean_squared_error(y_val, pred_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the mean square error of CatBoostRegressor is smaller, so use CatBoostRegressor model \n",
    "df_nan = fillNAN(df, df_nan, cat_measurement17, 'measurement_17', 'failure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_nan\n",
    "\n",
    "# we can use .info() to see the non-null count\n",
    "# df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "processing for more feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.isnull().sum(axis=1) is used to calculate all the missing value of columns\n",
    "df = df[(df.isnull().sum(axis=1) <= 1) | (df.failure == 2)]\n",
    "\n",
    "df = df[(df['loading'] < 300) | (df['failure'] == 2)]\n",
    "df = df[(df['measurement_1'] < 27) | (df['failure'] == 2)]\n",
    "\n",
    "# create some columns\n",
    "df['loading * mesh6'] = ((df['loading'] - df['loading'].min()) / df['loading'].max()) * ((df['measurement_6'] - df['measurement_6'].min()) / df['measurement_6'].max())\n",
    "df['loading * mesh6'] = df['measurement_17'] * df['loading * mesh6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the failure that is not equal to 2\n",
    "y = df[df.failure != 2].failure.values\n",
    "# test_df get the failure that is equal to 2\n",
    "test_df = df[df.failure == 2]\n",
    "# get the column that the failure is not equal to 2 and drop the failure and product_code column\n",
    "X_res = df[df.failure != 2].drop(['failure',  'product_code'], axis=1)\n",
    "\n",
    "# drop the failure column and product_code(failure column is the label and product_code is not important for training)\n",
    "x_test = test_df.drop(['failure', 'product_code'], axis=1)\n",
    "\n",
    "# import SimpleImputer\n",
    "# SimpleImputer can fill in the missing value\n",
    "from sklearn.impute import SimpleImputer\n",
    "# the strategy is mean represents that we are going to use mean to fill in the missing data\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer = imputer.fit(X_res)\n",
    "  \n",
    "X = imputer.transform(X_res)\n",
    "\n",
    "# same for the test data\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imputer = imputer.fit(x_test)\n",
    "X_test = imputer.transform(x_test)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.01, random_state=42, shuffle=True, stratify= y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mutual_info_classif is used to Estimate mutual information for a discrete target variable.\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    " \n",
    "X_T = pd.DataFrame(data=X, columns = X_res.columns)\n",
    "\n",
    "MI_score = mutual_info_classif(X_T, y)\n",
    "MI_score = pd.Series(MI_score, name=\"MI Scores\", index=X_T.columns)\n",
    "\n",
    "# sort the values of ascending order\n",
    "MI_score = MI_score.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LGBMRegressor(max_depth = 15, num_leaves = 2, min_data_in_leaf = 450, \n",
    "                        num_iterations = 50, feature_fraction = 0.8,\n",
    "                        bagging_freq = 7, bagging_fraction = 0.6,\n",
    "                        learning_rate = 0.15\n",
    "                    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=450, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=450\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(bagging_fraction=0.6, bagging_freq=7, feature_fraction=0.8,\n",
       "              learning_rate=0.15, max_depth=15, min_data_in_leaf=450,\n",
       "              num_iterations=50, num_leaves=2)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC Score =  0.6822\n"
     ]
    }
   ],
   "source": [
    "y_light_valid = model.predict(X_val)\n",
    "\n",
    "roc_score_dummy = roc_auc_score(y_val, y_light_valid)\n",
    "print(f\"ROC Score = {roc_score_dummy : .4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC Score =  0.5953\n"
     ]
    }
   ],
   "source": [
    "y_light_train = model.predict(X_train)\n",
    "\n",
    "roc_score_dummy = roc_auc_score(y_train, y_light_train)\n",
    "print(f\"ROC Score = {roc_score_dummy : .4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cf92aa13fedf815d5c8dd192b8d835913fde3e8bc926b2a0ad6cc74ef2ba3ca2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
